
#added process_id to job - all the jobs associated with a single pipeline run are identified by this process_id


CREATE TABLE job (
  job_id             int(10) unsigned DEFAULT '0' NOT NULL auto_increment,
  process_id         varchar(100) DEFAULT 'NEW' NOT NULL,
  analysis_id        int(10) unsigned DEFAULT '0',
  queue_id           int(10) unsigned DEFAULT '0',
  stdout_file        varchar(100) DEFAULT '',
  stderr_file        varchar(100) DEFAULT '',
  object_file        varchar(100) DEFAULT '',
  status             varchar(20) DEFAULT 'NEW' NOT NULL,
  stage              varchar(20) DEFAULT '',
  time               datetime DEFAULT '0000-00-00 00:00:00' NOT NULL,
  retry_count        int default 0,

  PRIMARY KEY (job_id),
  KEY (process_id),
  KEY (analysis_id)
);

INSERT INTO job VALUES (1,'process1',3,0,'','','','NEW','','',2);
INSERT INTO job VALUES (2,'process1',3,0,'','','','NEW','','',2);


CREATE TABLE iohandler (
   iohandler_id         int(10) unsigned DEFAULT '0' NOT NULL auto_increment,
   dbadaptor_id         int(10) DEFAULT '0' NOT NULL,
   type                 enum ('INPUT','OUTPUT') NOT NULL,

   PRIMARY KEY (iohandler_id),
   KEY dbadaptor (dbadaptor_id)
);
INSERT INTO iohandler VALUES (1,2,'INPUT');
INSERT INTO iohandler VALUES (2,2,'OUTPUT');

# note-  the column type is meant for differentiating the input adaptors from the output adaptors
#        each analysis should only have ONE output adaptor.

CREATE TABLE datahandler(
    datahandler_id     int(10) unsigned NOT NULL auto_increment,
    iohandler_id        int(10) DEFAULT '0' NOT NULL,
    method              varchar(60) DEFAULT '' NOT NULL,
    argument            varchar(40) DEFAULT '' ,
    rank                int(10) DEFAULT 1 NOT NULL,

    PRIMARY KEY (datahandler_id),
    KEY iohandler (iohandler_id)
);
INSERT INTO datahandler VALUES (1,1,'get_PrimarySeqAdaptor','',1);
INSERT INTO datahandler VALUES (2,1,'fetch_by_dbID','1',2);
INSERT INTO datahandler VALUES (3,2,'get_SeqFeatureAdaptor','',1);
INSERT INTO datahandler VALUES (4,2,'store','OUTPUT',2);


CREATE TABLE dbadaptor (
   dbadaptor_id   int(10) unsigned DEFAULT '0' NOT NULL auto_increment,
   dbname         varchar(40) DEFAULT '' NOT NULL,
   driver         varchar (40) DEFAULT '' NOT NULL,
   host           varchar (40) DEFAULT '',
   user           varchar (40) DEFAULT '',
   pass           varchar (40) DEFAULT '',
   module         varchar (100) DEFAULT '',
   
   PRIMARY KEY (dbadaptor_id)
);

INSERT INTO dbadaptor VALUES (2,'bioperl_db','mysql','localhost','root','','SQL::DBAdaptor');

#modified input table to reflect only Fixed Inputs (Inputs that are filled up before the pipeline run
# and are different from the inputs generated during pipeline run

CREATE TABLE input (
   input_id         int(10) unsigned DEFAULT '0' NOT NULL auto_increment,
   name             varchar(40) DEFAULT '' NOT NULL,
   analysis_id      int(10) unsigned NOT NULL,
   iohandler_id     int(10) unsigned NOT NULL,
   process_id       int(10) unsigned NOT NULL,

   PRIMARY KEY (input_id),
   KEY iohandler (iohandler_id),
   KEY job (process_id)

);

INSERT INTO input VALUES (1,'input1',3,1,'process1');

# created new table to reflect the inputs generated (as outputs of an analysis)- currently an analysis can generate
# outputs as inputs only for the next analysis  
CREATE TABLE new_input (
  input_id         int(10) unsigned DEFAULT '0' NOT NULL auto_increment,
  job_id           int(10) unsigned DEFAULT '0' NOT NULL,
  name             varchar(40) DEFAULT '' NOT NULL,
  PRIMARY KEY (input_id)
  #PRIMARY KEY (job_id,name,new_input_ioh_id);
  
);
# table to map the iohandlers required for reading the new inputs generated by previous analysis
# there is a restriction that only one iohandler is permitted for one analysis to read the generated
#input from previous analysis (cant figure out how to map the iohandlers if there are multiple inputs)

CREATE TABLE new_input_ioh (
  analysis_id      int(10) unsigned NOT NULL,
  iohandler_id     int(10) unsigned NOT NULL,

  PRIMARY KEY (analysis_id, iohandler_id)

);

INSERT INTO new_input_ioh VALUES (3,1);

# Replaced Rule_goal and Rule_condition tables with rule table
# Different actions and their behavior
# NOTHING - the output of the previous analysis is not to be used as the input and so just use the fixed inputs that
# were set during the start of the pipeline
# UPDATE - convert the outputs of the previous analysis as inputs to the next analysis -creates one job per input
# WAITFORALL - the new job for the next analysis will be created only when all the jobs of the previous analysis are
# completed, the outputs of the previous jobs are not set as inputs to the next job
# WAITFORALL_AND_UPDATE - same as WAITFORALL but the outputs are set as inputs for the next job

CREATE TABLE rule (
  rule_id          int(10) unsigned DEFAULT'0' NOT NULL auto_increment,
  current          int(10) unsigned NOT NULL,
  next             int(10) unsigned NOT NULL,
  action           enum('WAITFORALL','WAITFORALL_AND_UPDATE','UPDATE','NOTHING'),
  
  PRIMARY KEY (rule_id)
);

INSERT INTO rule VALUES (1,3,4,'WAITFORALL_AND_UPDATE');

CREATE TABLE analysis (
  analysis_id      int(10) unsigned DEFAULT '0' NOT NULL auto_increment,
  created          datetime DEFAULT '0000-00-00 00:00:00' NOT NULL,
  logic_name       varchar(40) not null,
  runnable         varchar(80),
  db               varchar(120),
  db_version       varchar(40),
  db_file          varchar(120),
  program          varchar(80),
  program_version  varchar(40),
  program_file     varchar(80),
  parameters       varchar(80),
  gff_source       varchar(40),
  gff_feature      varchar(40),

  PRIMARY KEY (analysis_id)
);

INSERT INTO analysis VALUES (3,'0000-00-00 00:00:00','test','Bio::Pipeline::Runnable::TestRunnable','','','','','','','','','');
INSERT INTO analysis VALUES (4,'0000-00-00 00:00:00','test1','Bio::Pipeline::Runnable::TestRunnable','','','','','','','','','');


#changed the name to analysis_output_handler, inputs are handled in a different way as they
# are not associated with analysis alone but with specific job 
CREATE TABLE analysis_output_handler(
  analysis_id               int(10) NOT NULL,
  iohandler_id              int(10) NOT NULL,

  PRIMARY KEY (analysis_id,iohandler_id)

);

INSERT INTO analysis_output_handler VALUES (3,2);
INSERT INTO analysis_output_handler VALUES (4,2);


CREATE TABLE completed_jobs (
  completed_job_id      int(10) unsigned DEFAULT '0' NOT NULL auto_increment,
  analysis_id           int(10) unsigned DEFAULT '0',
  queue_id              int(10) unsigned DEFAULT '0',
  stdout_file           varchar(100) DEFAULT '' NOT NULL,
  stderr_file           varchar(100) DEFAULT '' NOT NULL,
  object_file           varchar(100) DEFAULT '' NOT NULL,
  time                  datetime DEFAULT '0000-00-00 00:00:00' NOT NULL,
  retry_count           int default 0,

  PRIMARY KEY (completed_job_id),
  KEY analysis (analysis_id)
);
